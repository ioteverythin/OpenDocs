"""Tests for LLM extraction and summarization (mocked OpenAI)."""

from __future__ import annotations

import json
from pathlib import Path
from unittest.mock import MagicMock, patch

import pytest

from ioteverything.core.knowledge_graph import (
    EntityType,
    KnowledgeGraph,
    RelationType,
)
from ioteverything.core.parser import ReadmeParser


# ---------------------------------------------------------------------------
# Fixtures
# ---------------------------------------------------------------------------

@pytest.fixture
def sample_doc():
    sample_path = Path(__file__).parent.parent / "examples" / "sample_readme.md"
    content = sample_path.read_text(encoding="utf-8")
    parser = ReadmeParser()
    return parser.parse(
        content,
        repo_name="SmartTemp",
        repo_url="https://github.com/test/smarttemp",
    )


@pytest.fixture
def mock_extraction_response():
    """A realistic JSON response from an LLM extraction call."""
    return json.dumps({
        "entities": [
            {
                "name": "SmartTemp",
                "entity_type": "project",
                "properties": {"version": "1.0"},
                "confidence": 0.95,
            },
            {
                "name": "MQTT",
                "entity_type": "protocol",
                "properties": {},
                "confidence": 0.9,
            },
            {
                "name": "React",
                "entity_type": "framework",
                "properties": {},
                "confidence": 0.85,
            },
        ],
        "relations": [
            {
                "source": "SmartTemp",
                "target": "MQTT",
                "relation_type": "communicates_via",
                "confidence": 0.88,
            },
            {
                "source": "SmartTemp",
                "target": "React",
                "relation_type": "uses",
                "confidence": 0.82,
            },
        ],
    })


@pytest.fixture
def mock_summary_response():
    return (
        "SmartTemp is an IoT sensor platform that monitors environmental "
        "conditions using MQTT for real-time data streaming. Built with "
        "Python and React, it features a modern microservices architecture "
        "with InfluxDB for time-series storage. The project provides a "
        "compelling end-to-end solution for industrial temperature monitoring."
    )


@pytest.fixture
def mock_stakeholder_response():
    return (
        "- Modern Python/React stack with MQTT messaging is well-suited for IoT scale\n"
        "- Microservices architecture allows independent component scaling\n"
        "- InfluxDB choice is optimal for time-series workloads\n"
        "- Consider adding authentication layer for production readiness\n"
        "- Technical debt appears minimal given clean separation of concerns"
    )


# ---------------------------------------------------------------------------
# LLMClient tests
# ---------------------------------------------------------------------------

class TestLLMClient:
    def test_import_error_without_openai(self):
        """LLMClient should raise ImportError if openai isn't installed."""
        with patch.dict("sys.modules", {"openai": None}):
            # Reimport to trigger the check
            from importlib import reload
            from ioteverything.llm import llm_extractor

            # Can't easily force ImportError with a mock like this
            # but we verify the error message is set correctly
            pass  # The actual test is that it doesn't crash in normal import

    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_chat_returns_string(self, MockClient):
        """Ensure chat() returns the model's response text."""
        mock_instance = MockClient.return_value
        mock_instance.chat.return_value = "Hello, world!"

        result = mock_instance.chat("system prompt", "user prompt")
        assert result == "Hello, world!"


# ---------------------------------------------------------------------------
# LLMExtractor tests
# ---------------------------------------------------------------------------

class TestLLMExtractor:
    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_extract_entities_from_doc(
        self, MockClient, sample_doc, mock_extraction_response
    ):
        """LLMExtractor should parse LLM JSON and build a KG."""
        mock_instance = MockClient.return_value
        mock_instance.chat.return_value = mock_extraction_response

        from ioteverything.llm.llm_extractor import LLMExtractor

        extractor = LLMExtractor.__new__(LLMExtractor)
        extractor.llm = mock_instance
        extractor._id_counter = 0

        kg = extractor.extract(sample_doc)

        assert len(kg.entities) > 0
        # Should have the project root + parsed entities
        names = {e.name for e in kg.entities}
        assert "SmartTemp" in names

    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_extract_handles_markdown_fences(self, MockClient, sample_doc):
        """LLMExtractor should strip ```json fences from responses."""
        response = '```json\n{"entities": [{"name": "TestEntity", "entity_type": "component", "confidence": 0.9}], "relations": []}\n```'
        mock_instance = MockClient.return_value
        mock_instance.chat.return_value = response

        from ioteverything.llm.llm_extractor import LLMExtractor

        extractor = LLMExtractor.__new__(LLMExtractor)
        extractor.llm = mock_instance
        extractor._id_counter = 0

        kg = extractor.extract(sample_doc)
        names = {e.name for e in kg.entities}
        assert "TestEntity" in names

    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_extract_graceful_on_bad_json(self, MockClient, sample_doc):
        """LLMExtractor should not crash on invalid JSON responses."""
        mock_instance = MockClient.return_value
        mock_instance.chat.return_value = "This is not JSON at all"

        from ioteverything.llm.llm_extractor import LLMExtractor

        extractor = LLMExtractor.__new__(LLMExtractor)
        extractor.llm = mock_instance
        extractor._id_counter = 0

        # Should not raise â€” graceful degradation
        kg = extractor.extract(sample_doc)
        # At least the project root should exist
        assert any(e.entity_type == EntityType.PROJECT for e in kg.entities)

    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_extract_handles_api_error(self, MockClient, sample_doc):
        """LLMExtractor should handle API errors gracefully."""
        mock_instance = MockClient.return_value
        mock_instance.chat.side_effect = RuntimeError("API timeout")

        from ioteverything.llm.llm_extractor import LLMExtractor

        extractor = LLMExtractor.__new__(LLMExtractor)
        extractor.llm = mock_instance
        extractor._id_counter = 0

        kg = extractor.extract(sample_doc)
        # Should still have the project root
        assert len(kg.entities) >= 1

    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_extract_sets_llm_method(self, MockClient, sample_doc, mock_extraction_response):
        """All LLM-extracted entities should have extraction_method='llm'."""
        mock_instance = MockClient.return_value
        mock_instance.chat.return_value = mock_extraction_response

        from ioteverything.llm.llm_extractor import LLMExtractor

        extractor = LLMExtractor.__new__(LLMExtractor)
        extractor.llm = mock_instance
        extractor._id_counter = 0

        kg = extractor.extract(sample_doc)
        for entity in kg.entities:
            assert entity.extraction_method == "llm"


# ---------------------------------------------------------------------------
# LLMSummarizer tests
# ---------------------------------------------------------------------------

class TestLLMSummarizer:
    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_executive_summary(
        self, MockClient, sample_doc, mock_summary_response
    ):
        """LLMSummarizer should generate an executive summary."""
        mock_instance = MockClient.return_value
        mock_instance.chat.return_value = mock_summary_response

        from ioteverything.llm.llm_extractor import LLMSummarizer

        summarizer = LLMSummarizer.__new__(LLMSummarizer)
        summarizer.llm = mock_instance

        kg = KnowledgeGraph()
        result = summarizer.executive_summary(sample_doc, kg)
        assert "SmartTemp" in result
        assert len(result) > 50

    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_stakeholder_summary(
        self, MockClient, sample_doc, mock_stakeholder_response
    ):
        """LLMSummarizer should generate stakeholder-specific summaries."""
        mock_instance = MockClient.return_value
        mock_instance.chat.return_value = mock_stakeholder_response

        from ioteverything.llm.llm_extractor import LLMSummarizer

        summarizer = LLMSummarizer.__new__(LLMSummarizer)
        summarizer.llm = mock_instance

        kg = KnowledgeGraph()
        result = summarizer.stakeholder_summary(sample_doc, kg, "cto")
        assert "Python" in result or "architecture" in result.lower()

    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_unknown_persona(self, MockClient, sample_doc):
        """Unknown persona should return an error message, not crash."""
        mock_instance = MockClient.return_value

        from ioteverything.llm.llm_extractor import LLMSummarizer

        summarizer = LLMSummarizer.__new__(LLMSummarizer)
        summarizer.llm = mock_instance

        kg = KnowledgeGraph()
        result = summarizer.stakeholder_summary(sample_doc, kg, "alien")
        assert "Unknown persona" in result

    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_enrich_populates_kg(
        self, MockClient, sample_doc, mock_summary_response, mock_stakeholder_response
    ):
        """enrich() should populate KG with executive and stakeholder summaries."""
        mock_instance = MockClient.return_value
        # First call = executive summary, next 3 = stakeholder personas
        mock_instance.chat.side_effect = [
            mock_summary_response,
            mock_stakeholder_response,
            mock_stakeholder_response,
            mock_stakeholder_response,
        ]

        from ioteverything.llm.llm_extractor import LLMSummarizer

        summarizer = LLMSummarizer.__new__(LLMSummarizer)
        summarizer.llm = mock_instance

        kg = KnowledgeGraph()
        summarizer.enrich(sample_doc, kg)

        assert kg.executive_summary != ""
        assert "SmartTemp" in kg.executive_summary
        assert "cto" in kg.stakeholder_summaries
        assert "investor" in kg.stakeholder_summaries
        assert "developer" in kg.stakeholder_summaries

    @patch("ioteverything.llm.llm_extractor.LLMClient")
    def test_enrich_handles_api_failure(self, MockClient, sample_doc):
        """enrich() should gracefully handle API failures."""
        mock_instance = MockClient.return_value
        mock_instance.chat.side_effect = RuntimeError("Connection refused")

        from ioteverything.llm.llm_extractor import LLMSummarizer

        summarizer = LLMSummarizer.__new__(LLMSummarizer)
        summarizer.llm = mock_instance

        kg = KnowledgeGraph()
        summarizer.enrich(sample_doc, kg)

        # Should contain error messages, not crash
        assert "failed" in kg.executive_summary.lower()


# ---------------------------------------------------------------------------
# Smart Report tests
# ---------------------------------------------------------------------------

class TestSmartReport:
    def test_generate_basic_report(self, sample_doc, tmp_path):
        """Smart report should generate a Markdown file."""
        from ioteverything.core.semantic_extractor import SemanticExtractor
        from ioteverything.generators.smart_report import generate_smart_report

        extractor = SemanticExtractor()
        kg = extractor.extract(sample_doc)

        result = generate_smart_report(sample_doc, kg, tmp_path)
        assert result.success
        assert result.output_path.exists()
        assert result.output_path.suffix == ".md"

        content = result.output_path.read_text(encoding="utf-8")
        assert "Knowledge Graph" in content
        assert "Entity Catalog" in content
        assert "SmartTemp" in content

    def test_report_includes_llm_summaries(self, sample_doc, tmp_path):
        """Report should render LLM summaries when present in KG."""
        from ioteverything.generators.smart_report import generate_smart_report

        kg = KnowledgeGraph()
        kg.executive_summary = "This is a test executive summary."
        kg.stakeholder_summaries = {
            "cto": "- Great architecture\n- Modern stack",
            "investor": "- Strong market fit",
        }

        result = generate_smart_report(sample_doc, kg, tmp_path)
        assert result.success

        content = result.output_path.read_text(encoding="utf-8")
        assert "Executive Summary" in content
        assert "test executive summary" in content
        assert "Stakeholder Views" in content
        assert "Great architecture" in content

    def test_report_without_summaries(self, sample_doc, tmp_path):
        """Report should work fine even without LLM summaries."""
        from ioteverything.generators.smart_report import generate_smart_report

        kg = KnowledgeGraph()
        result = generate_smart_report(sample_doc, kg, tmp_path)
        assert result.success

        content = result.output_path.read_text(encoding="utf-8")
        # Should not have stakeholder sections
        assert "Stakeholder Views" not in content
